{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33605979-95f4-40c7-96c2-8ee306e36c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12aed922-ddd8-4a5c-9f6c-dfe3fb5f7b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randint = torch.randint(-100,100,(6,))\n",
    "randint\n",
    "randint2 = torch.randint(5,(5,))\n",
    "randint2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c23e6d1-d81d-427e-9f1c-1e5c8d81d204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 1.2000],\n",
       "        [2.2000, 3.1000],\n",
       "        [4.9000, 5.2000]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[0.1,1.2],[2.2,3.1],[4.9,5.2]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df0346db-11ab-42b0-a491-5d0952182277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(2,3)\n",
    "zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4abe8a23-f5dc-4597-9534-b5803af8622f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(3,4)\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b6b6a9c-2e5d-4024-bcc7-55eccd84bf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.empty(2,3)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ad5f80a-8b5f-4caa-a138-d9c09e4d83ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arange = torch.arange(5)\n",
    "arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "074332f6-2f01-4452-8026-e2f90cead83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.0000,  4.7500,  6.5000,  8.2500, 10.0000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linspace = torch.linspace(3,10,steps=5)\n",
    "linspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f27a80c7-2813-42cd-b9f7-155974a57cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+10, 1.0000e+10, 1.0000e+10, 1.0000e+10, 1.0000e+10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logspace = torch.logspace(start=10,end=10,steps = 5)\n",
    "logspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc8a71e2-f776-45cd-a9d5-beee149a4d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eye = torch.eye(5)\n",
    "eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5412115-3b0c-4ffd-91b1-2f9b1e9ead22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.empty((2,3),dtype = torch.int64)\n",
    "empty_like = torch.empty_like(a)\n",
    "empty_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42313ca1-24a1-4471-8933-93047d58a0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0941f086-ac15-4d0a-b58b-e9394a18a069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 1, 1, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = torch.tensor([0.1,0.9])\n",
    "\n",
    "samples = torch.multinomial(probabilities, num_samples = 10,replacement = True)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12b639af-25e3-4d8e-8b7e-60de987eb22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3,4])\n",
    "## concatination\n",
    "out = torch.cat((tensor,torch.tensor([5])),dim = 0)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "613301df-f73c-4053-b6e3-1861523e3b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-43,  92, -26,  24, -36],\n",
       "        [  0,  24,  69,  10,  58],\n",
       "        [  0,   0, -93,  67,  42],\n",
       "        [  0,   0,   0,  13,  52],\n",
       "        [  0,   0,   0,   0,  64]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## triangle upper triu\n",
    "\n",
    "out = torch.triu(torch.randint(-100,100,(5,5)))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fb59b5c-637f-4a43-8608-5efc5124d125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.tril(torch.ones(5,5))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bff1090-c2f9-4708-ab07-098a7089cbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.zeros(5,5).masked_fill(torch.tril(torch.ones(5,5)) == 0, float('-inf'))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e19003b-713b-4b9b-bdb5-ea6bab360445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4397e24e-a72a-452b-9393-0c63ff34a15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.zeros(2,3,4)\n",
    "out = input.transpose(0,2)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e53d74c1-9bfc-4f9a-b3e9-631f37cb2dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.tensor([1,2,3])\n",
    "tensor2 = torch.tensor([4,5,6])\n",
    "tensor3 = torch.tensor([7,8,9])\n",
    "\n",
    "stacked_tensor = torch.stack([tensor1,tensor2,tensor3])\n",
    "stacked_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "451ac6ce-68ec-42f0-8568-dc716871fbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-9.2025, -0.6160, -6.4558], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "sample = torch.tensor([10.,10.,10.])\n",
    "linear = nn.Linear(3,3,bias = False)\n",
    "print(linear(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7921a065-76a4-4107-8a2f-c4228134c0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "tensor1 = torch.tensor([1.0,2.0,3.0])\n",
    "softmax_output = F.softmax(tensor1,dim=0)\n",
    "\n",
    "print(softmax_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d9e14ee-d739-4649-9b27-c799e3646f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 100])\n"
     ]
    }
   ],
   "source": [
    "## embeddings\n",
    "vocab_size = 1000\n",
    "embedding_dim = 100\n",
    "embedding = nn.Embedding(vocab_size,embedding_dim)\n",
    "\n",
    "input_indices = torch.LongTensor([1,5,3,2])\n",
    "\n",
    "embedded_output = embedding(input_indices)\n",
    "\n",
    "print(embedded_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c2fbfa7-2a4d-42ee-a0c7-cadd8bf1cc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "b = torch.tensor([[7,8,9],[10,11,12]])\n",
    "\n",
    "a @ b\n",
    "torch.matmul(a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ba70af1-59d2-4b5d-af1e-6184d516680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_64 = torch.randint(1,(3,2)).float()\n",
    "\n",
    "float_32 = torch.rand(2,3)\n",
    "\n",
    "result = torch.matmul(int_64,float_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f884d57c-de21-4e4c-9338-b7518c3fa00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n",
      "torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2,3,5)\n",
    "print(a.shape)\n",
    "x,y,z = a.shape\n",
    "a = a.view(x,y,z)\n",
    "# print(x,y,z)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19454819-521d-407e-91e4-d432e1a66f3b",
   "metadata": {},
   "source": [
    "Shape: (2, 3, 4)\n",
    "\n",
    "logits = tensor([\n",
    "    [  # First sequence in the batch\n",
    "        [0.1, 0.2, 0.3, 0.4],  # First token's embedding\n",
    "        [0.5, 0.6, 0.7, 0.8],  # Second token's embedding\n",
    "        [0.9, 1.0, 1.1, 1.2]   # Third token's embedding\n",
    "    ],\n",
    "    [  # Second sequence in the batch\n",
    "        [1.3, 1.4, 1.5, 1.6],  # First token's embedding\n",
    "        [1.7, 1.8, 1.9, 2.0],  # Second token's embedding\n",
    "        [2.1, 2.2, 2.3, 2.4]   # Third token's embedding\n",
    "    ]\n",
    "])\n",
    "\n",
    "##### First Dimension (B = 2): There are 2 sequences in the batch.\n",
    "##### Second Dimension (T = 3): Each sequence has 3 tokens.\n",
    "##### Third Dimension (C = 4): Each token is represented by a 4-dimensional embedding vector.\n",
    "\n",
    "logits = tensor([\n",
    "    [[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8], [0.9, 1.0, 1.1, 1.2]],\n",
    "    [[1.3, 1.4, 1.5, 1.6], [1.7, 1.8, 1.9, 2.0], [2.1, 2.2, 2.3, 2.4]]\n",
    "])  # Shape: (2, 3, 4)\n",
    "\n",
    "targets = tensor([\n",
    "    [0, 1, 2],\n",
    "    [1, 2, 3]\n",
    "])  # Shape: (2, 3)\n",
    "\n",
    "\n",
    "logits = logits.view(2 * 3, 4)  # Shape: (6, 4)\n",
    "targets = targets.view(2 * 3)   # Shape: (6)\n",
    "\n",
    "\n",
    "logits = tensor([\n",
    "    [0.1, 0.2, 0.3, 0.4],\n",
    "    [0.5, 0.6, 0.7, 0.8],\n",
    "    [0.9, 1.0, 1.1, 1.2],\n",
    "    [1.3, 1.4, 1.5, 1.6],\n",
    "    [1.7, 1.8, 1.9, 2.0],\n",
    "    [2.1, 2.2, 2.3, 2.4]\n",
    "])  # Shape: (6, 4)\n",
    "\n",
    "targets = tensor([0, 1, 2, 1, 2, 3])  # Shape: (6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7c3ac2f-160e-4bd6-a02e-8c0c6aecda3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(6, 6) This is the embedding\n",
      "tensor([[[-0.9401,  0.4899,  1.1737,  0.6869, -0.0865, -1.1344],\n",
      "         [ 0.3351,  0.3462, -1.9393,  0.6430, -1.1752,  1.3683],\n",
      "         [ 0.4847,  0.2558,  0.8049, -0.3266,  1.6236,  0.2143]],\n",
      "\n",
      "        [[ 0.3351,  0.3462, -1.9393,  0.6430, -1.1752,  1.3683],\n",
      "         [ 0.7900, -0.5231,  1.9024, -0.7804, -1.3707,  0.5472],\n",
      "         [ 2.3455, -0.3964,  0.2356, -0.2217,  0.8984,  0.0528]]],\n",
      "       grad_fn=<EmbeddingBackward0>) this is logits\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "vocab_size = 6\n",
    "token_embedding_table = nn.Embedding(vocab_size,vocab_size)\n",
    "print(token_embedding_table,'This is the embedding')\n",
    "\n",
    "\n",
    "index = torch.tensor([[0, 1, 2],[1,4,5]])\n",
    "\n",
    "\n",
    "logits = token_embedding_table(index)\n",
    "print(logits,'this is logits')\n",
    "b,t,c = logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdee0a6f-5fd9-417a-9021-6148539dbc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9401,  0.4899,  1.1737,  0.6869, -0.0865, -1.1344],\n",
       "        [ 0.3351,  0.3462, -1.9393,  0.6430, -1.1752,  1.3683],\n",
       "        [ 0.4847,  0.2558,  0.8049, -0.3266,  1.6236,  0.2143],\n",
       "        [ 0.3351,  0.3462, -1.9393,  0.6430, -1.1752,  1.3683],\n",
       "        [ 0.7900, -0.5231,  1.9024, -0.7804, -1.3707,  0.5472],\n",
       "        [ 2.3455, -0.3964,  0.2356, -0.2217,  0.8984,  0.0528]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = logits.view(b*t,c)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "302ac33c-a6da-4753-b384-534175aa3677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1000, 0.4000, 0.7000, 1.0000, 1.3000],\n",
       "         [0.2000, 0.5000, 0.8000, 1.1000, 1.4000],\n",
       "         [0.3000, 0.6000, 0.9000, 1.2000, 1.5000]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.tensor([\n",
    "    [\n",
    "        [0.1, 0.2, 0.3],  # First token in the first sequence\n",
    "        [0.4, 0.5, 0.6],  # Second token in the first sequence\n",
    "        [0.7, 0.8, 0.9],  # Third token in the first sequence\n",
    "        [1.0, 1.1, 1.2],  # Fourth token in the first sequence  \n",
    "        [1.3, 1.4, 1.5]\n",
    "    ]]) # Fifth token in the first sequence\n",
    "\n",
    "# print(logits[:,-1,:])\n",
    "\n",
    "#     ],\n",
    "\n",
    "\n",
    "#     [\n",
    "#         [1.6, 1.7, 1.8],  # First token in the second sequence\n",
    "#         [1.9, 2.0, 2.1],  # Second token in the second sequence\n",
    "#         [2.2, 2.3, 2.4],  # Third token in the second sequence\n",
    "#         [2.5, 2.6, 2.7],  # Fourth token in the second sequence\n",
    "#         [2.8, 2.9, 3.0]   # Fifth token in the second sequence\n",
    "#     ]\n",
    "# ]) \n",
    "logits.transpose(-2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cab06e64-cbd9-4f52-9dec-a2dcf56d5f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = [0.0235, 0.0038, 0.0121, 0.0039, 0.0073, 0.0045, 0.0076, 0.0185, 0.0056,\n",
    "         0.0105, 0.0051, 0.0043, 0.0099, 0.0022, 0.0007, 0.0010, 0.0202, 0.0159,\n",
    "         0.0320, 0.0020, 0.0003, 0.0089, 0.0091, 0.0037, 0.0046, 0.0026, 0.0041,\n",
    "         0.0068, 0.0088, 0.0100, 0.0026, 0.0192, 0.0667, 0.0144, 0.0041, 0.0214,\n",
    "         0.0103, 0.0325, 0.0361, 0.0035, 0.0110, 0.0074, 0.0137, 0.0028, 0.0074,\n",
    "         0.0083, 0.0064, 0.0034, 0.0051, 0.0032, 0.0677, 0.0018, 0.0018, 0.0109,\n",
    "         0.0033, 0.0072, 0.0035, 0.0214, 0.0084, 0.0061, 0.0207, 0.0080, 0.0153,\n",
    "         0.0144, 0.0025, 0.0276, 0.0797, 0.0107, 0.0024, 0.0223, 0.0454, 0.0202,\n",
    "         0.0100, 0.0096, 0.0045, 0.0046, 0.0266, 0.0055, 0.0013, 0.0027, 0.0047]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9256ea5-e222-452b-8195-691272d6175e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 18.78175163269043\n",
      "Gradients before zeroing: tensor([[-17.3352]])\n",
      "Gradients after zeroing: None\n",
      "Updated weight: -0.16689586639404297\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Example model with a single linear layer\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1, bias=False)  # Linear layer: y = wx\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleModel()\n",
    "\n",
    "# Example data\n",
    "x_train = torch.tensor([[2.0]], requires_grad=True)\n",
    "y_train = torch.tensor([[4.0]])\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(x_train)\n",
    "loss = criterion(outputs, y_train)\n",
    "\n",
    "# Print initial loss\n",
    "print(f\"Initial loss: {loss.item()}\")\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()\n",
    "\n",
    "# Print gradients\n",
    "print(f\"Gradients before zeroing: {model.linear.weight.grad}\")\n",
    "\n",
    "# Zero gradients\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Print gradients after zeroing\n",
    "print(f\"Gradients after zeroing: {model.linear.weight.grad}\")\n",
    "\n",
    "# Update parameters\n",
    "optimizer.step()\n",
    "\n",
    "# Print updated weight\n",
    "print(f\"Updated weight: {model.linear.weight.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e8d3da9-7227-435d-844d-a801440097eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "token_embedding_table = nn.Embedding(vocab_size,vocab_size)\n",
    "context = torch.zeros((1,1),dtype = torch.long)\n",
    "print(context)\n",
    "# print(token_embedding_table(context))\n",
    "# print(token_embedding_table(logits))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b58ed1c2-223c-418a-afb7-2f46fc23c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = ['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\ufeff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3fb6cf7-da44-42f9-8272-486c53579b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_int = {ch:i for i, ch in enumerate(chars)}\n",
    "int_to_string = {i:ch for i ,ch in enumerate(chars)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c36e306e-fe1b-4f87-9f94-402fbf9fa2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_string[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a905cf47-96e5-46d0-93a2-85cc4f9eff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee085919-a62d-407d-8f8a-3816fa4c61ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61, 58, 65, 65, 68]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = encode('hello')\n",
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "642f4f1e-f3f2-4cde-a9d5-b092480d677a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d665e6b-60aa-4ef3-9bc7-bb4babf645e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
